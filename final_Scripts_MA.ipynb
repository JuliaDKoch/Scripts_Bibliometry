{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa47569c-2e88-4112-be3f-a3a6cbc1cfaa",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# setup: \n",
        "import csv #for CSV handling\n",
        "import re #for regular expressions handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "330f821a-a988-4299-bd62-5258d92a70a5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# check whether columns have the right title, if so, name them for easier handling \n",
        "def set_column_name(column_name, column_number, column_title):\n",
        "    if header[column_number] != column_title:\n",
        "        print('Error at', column_name,  'column number')\n",
        "        sys.exit(1) # evtl Luft nach oben bei dem Befehl hier\n",
        "    else: column_name = column_number"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a4d441d-1733-491d-9f58-36d9b98f4311",
      "metadata": {},
      "source": [
        "For 5.5: Process KATI data on Internationality, Step 1: calculate for each year and each number of countries how many single/multiple author papers there are with this number of countries involved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "508c10f0-dee3-4d00-8daf-d2f4dc5cf935",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "source_file_name = '.csv'  #input are \"Internationality\" files which have been brought to CSV format without \" manually\n",
        "with open(source_file_name, 'r') as source_file:\n",
        "    reader = csv.reader(source_file, delimiter = ';')\n",
        "    header = next(reader)\n",
        "    print(header)\n",
        "    set_column_name(year_column, 1, 'year')\n",
        "    set_column_name(number_countries_column, 4, 'countryCount')\n",
        "    set_column_name(number_authors_column, 2, 'Nauthor')\n",
        "    data = {}     #sort data by year and make it accessible by year\n",
        "    for row in reader:\n",
        "        year = row[year_column]\n",
        "        if year not in data:\n",
        "            data[year] = [row]\n",
        "        else: \n",
        "            data[year].append(row)\n",
        "    with open(source_file_name.rstrip('.csv')+'_country_numbers_raw.csv', 'w', newline='') as target_file:\n",
        "        writer = csv.writer(target_file)\n",
        "        header = ['year', '#countries', 'document count single author', 'document count multiple authors']\n",
        "        writer.writerow(header)\n",
        "        for year in data:\n",
        "            max_num_countries = max(int(row[number_countries_column]) for row in data[year])\n",
        "            print (year, '   ', max_num_countries) #for plausibility check while running\n",
        "            for this_num_countries in range(0,max_num_countries+1): \n",
        "                counter_this_num_countries_single_author = 0 #count single-author papers seperately\n",
        "                counter_this_num_countries_multiple_authors = 0\n",
        "                for row in data[year]:\n",
        "                    if int(row[number_countries_column]) == this_num_countries:\n",
        "                        if int(row[number_authors_column]) == 1:\n",
        "                            counter_this_num_countries_single_author += 1 \n",
        "                        else:\n",
        "                            counter_this_num_countries_multiple_authors += 1\n",
        "                writer.writerow([year, this_num_countries, counter_this_num_countries_single_author, counter_this_num_countries_multiple_authors])\n",
        "                \n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c384805f-f573-4f94-afeb-c3d7165fc790",
      "metadata": {},
      "source": [
        "For 5.5.: Step 2: aggregate into clusters of numbers and return maximal number of countries per year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d561040-a380-4adf-9cfd-a8a4301c2a04",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "source_file_name = ''  #input are \"Internationality\" files which have been brought to CSV format without \" manually\n",
        "with open(source_file_name, 'r') as source_file:\n",
        "    reader = csv.reader(source_file, delimiter = ';')\n",
        "    header = next(reader)\n",
        "    print(header)\n",
        "    set_column_name(year_column, 1, 'year')\n",
        "    set_column_name(number_countries_column, 4, 'countryCount')\n",
        "    set_column_name(number_authors_column, 2, 'Nauthor')\n",
        "    data = {}\n",
        "    for row in reader:\n",
        "        year = row[year_column]\n",
        "        if year not in data:\n",
        "            data[year] = [row]\n",
        "        else: \n",
        "            data[year].append(row)\n",
        "    with open(source_file_name.rstrip('.csv')+'_country_numbers_aggr.csv', 'w', newline='') as target_file:\n",
        "        writer = csv.writer(target_file)\n",
        "        header = ['year', '#:0country', '#:1country1author', '#:1country_more_authors', '#:2countries', '#:3-5countries', '#:6-10countries','#:>=11countries', 'max # of countries']\n",
        "        writer.writerow(header)\n",
        "        for year in data:\n",
        "            max_num_countries = max(int(row[number_countries_column]) for row in data[year])\n",
        "            print (year, '   ', max_num_countries)\n",
        "            counter_no_country = 0\n",
        "            counter_1_country_1_author = 0\n",
        "            counter_1_country_more_authors = 0\n",
        "            counter_2_countries = 0\n",
        "            counter_3_to_5_countries = 0\n",
        "            counter_6_to_10_countries = 0\n",
        "            counter_many_countries = 0\n",
        "            for this_num_countries in range(0,max_num_countries+1):\n",
        "                counter_this_num_countries_single_author = 0\n",
        "                counter_this_num_countries_multiple_authors = 0\n",
        "                temp_count_3_to_5 = 0\n",
        "                temp_count_6_to_10 = 0\n",
        "                temp_count_many = 0\n",
        "                for row in data[year]:\n",
        "                    if int(row[number_countries_column]) == this_num_countries:\n",
        "                            if int(row[number_authors_column]) == 1:\n",
        "                                counter_this_num_countries_single_author += 1 \n",
        "                            else:\n",
        "                                counter_this_num_countries_multiple_authors += 1\n",
        "                if this_num_countries == 0:\n",
        "                   counter_no_country = counter_this_num_countries_single_author + counter_this_num_countries_multiple_authors\n",
        "                else:\n",
        "                    if this_num_countries == 1:\n",
        "                       counter_1_country_1_author = counter_this_num_countries_single_author\n",
        "                       counter_1_country_more_authors = counter_this_num_countries_multiple_authors\n",
        "                    else:\n",
        "                        if this_num_countries == 2:\n",
        "                            counter_2_countries = counter_this_num_countries_single_author + counter_this_num_countries_multiple_authors\n",
        "                        else:\n",
        "                            if 3 <= this_num_countries <= 5:\n",
        "                               temp_count_3_to_5 = counter_this_num_countries_single_author + counter_this_num_countries_multiple_authors\n",
        "                            else:\n",
        "                                if 6 <= this_num_countries <= 10:\n",
        "                                   counter_6_to_10_countries = counter_this_num_countries_single_author + counter_this_num_countries_multiple_authors\n",
        "                                else:\n",
        "                                     temp_count_many = counter_this_num_countries_single_author + counter_this_num_countries_multiple_authors\n",
        "                counter_3_to_5_countries += temp_count_3_to_5 \n",
        "                counter_6_to_10_countries += temp_count_6_to_10\n",
        "                counter_many_countries += temp_count_many\n",
        "            writer.writerow([year, counter_no_country,counter_1_country_1_author, counter_1_country_more_authors, counter_2_countries, counter_3_to_5_countries, counter_6_to_10_countries, counter_many_countries, max_num_countries])\n",
        "    \n",
        "print('done')\n",
        "#final grouping into single author, national, international was done directly in Excel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c14f0d4-9c2d-4586-af94-156d44f8ea44",
      "metadata": {},
      "source": [
        "For 5.2: Preprocess country data by clustering by periods; check for country name issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92f9a4b8-ec55-48d4-aef6-3ec996b60147",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "source_file_name = 'Countries_List.csv'  \n",
        "with open(source_file_name, 'r') as source_file:\n",
        "    reader = csv.reader(source_file, delimiter = '\"') #use \" as delimiter to avoid trouble with the commata in the names\n",
        "    header = next(reader)\n",
        "    print(header)\n",
        "    set_column_name(year_column, 1, 'year')\n",
        "    set_column_name(country_name_column, 3, 'countryLabel')\n",
        "    set_column_name(country_tag_column, 5, 'iso3')\n",
        "    set_column_name(pub_num_column, 7, 'N_pub')\n",
        "    set_column_name(continent_column, 11, 'continentLabel')\n",
        "    data = {}\n",
        "    for row in reader:\n",
        "        country_tag = row[country_tag_column]\n",
        "        if country_tag not in data:\n",
        "            data[country_tag] = [row]\n",
        "        else: \n",
        "            data[country_tag].append(row)\n",
        "    with open(source_file_name.rstrip('.csv')+'_aggr_periods.csv', 'w', newline='') as target_file:\n",
        "        writer = csv.writer(target_file)\n",
        "        header = ['Continent', 'Country Name', '#Publications 1970-1999', '#Publications 2000-2009', '#Publications 2010-2020', '#Publications 2020-2025']\n",
        "        writer.writerow(header)\n",
        "        for iso3 in data:\n",
        "            counter_to_1999 = 0\n",
        "            counter_2000_2009 = 0\n",
        "            counter_2010_2019 = 0\n",
        "            counter_from_2020 = 0\n",
        "            countryLabel = ''\n",
        "            continent = ''\n",
        "            for row in data[iso3]:\n",
        "                if countryLabel != str(row[country_name_column]) and countryLabel != '':\n",
        "                    print(iso3, ' has two names: ', countryLabel, ' and ', str(row[country_name_column])) #check if country names are ambiguous\n",
        "                if int(row[year_column]) <= 1999:\n",
        "                    counter_to_1999 += int(row[pub_num_column])\n",
        "                else:\n",
        "                    if 2000 <= int(row[year_column]) <= 2009:\n",
        "                        counter_2000_2009 += int(row[pub_num_column])\n",
        "                    else:\n",
        "                        if 2010 <= int(row[year_column]) <= 2019:\n",
        "                            counter_2010_2019 += int(row[pub_num_column])\n",
        "                        else: \n",
        "                             counter_from_2020 += int(row[pub_num_column])\n",
        "                countryLabel = str(row[country_name_column])\n",
        "                if str(row[continent_column]).endswith('america'):\n",
        "                    continent =  str(row[continent_column]).rstrip('america').capitalize() + ' America'\n",
        "                else: \n",
        "                    continent = str(row[continent_column]).capitalize()\n",
        "            writer.writerow([continent, countryLabel,counter_to_1999, counter_2000_2009, counter_2010_2019, counter_from_2020 ])\n",
        "  \n",
        "\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4474fe6-d302-45cd-ad50-c13df07d0376",
      "metadata": {},
      "source": [
        "For 5.7 : Preprocess Country Data by collect DACH, UK, US data per year; as well as total number per year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ae51ef-ddea-4ebd-95ee-c4632877b58d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "source_file_name = 'Countries_List.csv'  \n",
        "with open(source_file_name, 'r') as source_file:\n",
        "    reader = csv.reader(source_file, delimiter = '\"') #use \" as delimiter to avoid trouble with the commata in the names\n",
        "    header = next(reader)\n",
        "    print(header)\n",
        "    set_column_name(year_column, 1, 'year')\n",
        "    set_column_name(country_name_column, 3, 'countryLabel')\n",
        "    set_column_name(country_tag_column, 5, 'iso3')\n",
        "    set_column_name(pub_num_column, 7, 'N_pub')\n",
        "    set_column_name(continent_column, 11, 'continentLabel')\n",
        "    data = {}\n",
        "    for row in reader:\n",
        "        year = row[year_column]\n",
        "        if year not in data:\n",
        "            data[year] = [row]\n",
        "        else: \n",
        "            data[year].append(row)\n",
        "    with open(source_file_name.rstrip('.csv')+'_DACH_UK_US_all.csv', 'w', newline='') as target_file:\n",
        "        writer = csv.writer(target_file)\n",
        "        header = ['Year', '#Pubs DACH', '#Pubs UK', '#Pubs US', '# all Pubs']\n",
        "        writer.writerow(header)\n",
        "        for year in data:\n",
        "            counter_DACH = 0\n",
        "            counter_UK = 0\n",
        "            counter_US = 0\n",
        "            counter_all = 0\n",
        "            for row in data[year]:\n",
        "                iso3 = row[country_tag_column]\n",
        "                counter_all += int(row[pub_num_column])\n",
        "                if iso3 == 'deu' or iso3 == 'aut' or iso3 == 'che':\n",
        "                    counter_DACH += int(row[pub_num_column])\n",
        "                if iso3 == 'gbr':\n",
        "                    counter_UK += int(row[pub_num_column])\n",
        "                if iso3 == 'usa':\n",
        "                    counter_US += int(row[pub_num_column])\n",
        " \n",
        "            #print(iso3, ' ', counter_to_1999, counter_2000_2009, counter_2010_2019, counter_from_2020)\n",
        "            writer.writerow([year, counter_DACH, counter_UK, counter_US, counter_all])\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9830ccf6-8fee-441c-ad85-ec469f9c9662",
      "metadata": {},
      "source": [
        "For 5.4: Clean name data in co-publication files by bringing all names to 'Last name, Initial' format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d110c11-eb5a-4a8e-bf2d-fac85b16636d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "source_file_name = 'Koauthor List Fullerene.csv'  \n",
        "with open(source_file_name, 'r') as source_file:\n",
        "    reader = csv.reader(source_file, delimiter = '\"') # use \" (around all strings in the source file) as the read-delimiter to avoid trouble with the commata in the names\n",
        "    header = next(reader)\n",
        "    print(header)\n",
        "    set_column_name(ID_column, 1, 'uid')\n",
        "    set_column_name(year_column, 3, 'year')\n",
        "    set_column_name(names_column, 5, 'author_list')\n",
        "    with open(source_file_name.rstrip('.csv')+'_clean_names.csv', 'w', newline='') as target_file: # \"intermediate\" file for QA purposes\n",
        "            writer = csv.writer(target_file)\n",
        "            header = ['ID', 'year', 'authors']\n",
        "            writer.writerow(header)\n",
        "            for row in reader: \n",
        "                #if len(row) >= 6: \n",
        "                    authors_list = []\n",
        "                    name = str(row[names_column]).title()\n",
        "                    # bring all names to format with capitalised first letter, rest in lower case\n",
        "                    names_list = name.split('|')\n",
        "                    # split at '|‘ (delimiter between different author names) \n",
        "                    for name in names_list:\n",
        "                        name_split = [string.strip() for string in name.split(',')]\n",
        "                        # split each name at comma between last name and first names, and remove all leading/trailing white spaces\n",
        "                        if len(name_split) > 1: \n",
        "                            name_clean = name_split[0] + ', ' + name_split[1][0]\n",
        "                        else: \n",
        "                            name_clean = name_split[0] + ', ' \n",
        "                        # cleaned name is of format [last name], [first initial], unless no info about first name(s) is given; name format in this case is [last name], [blank]\n",
        "                        if name_clean not in authors_list:\n",
        "                            authors_list.append(name_clean)\n",
        "                            # add cleaned name to authors' list unless it is already there\n",
        "                    ID = row[ID_column]\n",
        "                    year = row[year_column]\n",
        "                    writer.writerow([ID, year, authors_list])\n",
        "print('Done')\n",
        "# POTENTIAL IMPROVEMENT: catch different spellings of last names (Müller vs Mueller etc.)\n",
        "   \n",
        "    \n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cd737e5-527a-42cf-b800-de03730d0452",
      "metadata": {},
      "source": [
        "For 5.4: Create list of co-publication graph edges "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8946ea3-c7da-437f-b587-8dbe6001696a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "source_file_name = 'Koauthor List Fullerene_clean_names.csv'  \n",
        "with open(source_file_name, 'r') as source_file:\n",
        "    reader = csv.reader(source_file, delimiter = ',') \n",
        "    header = next(reader)\n",
        "    print(header)\n",
        "    set_column_name(authors_column, 2, 'authors')\n",
        "    set_column_name(year_column, 1, 'year')\n",
        "    next_author_id = 0 \n",
        "    author_ids = {}\n",
        "    def author_id(author):\n",
        "        global next_author_id\n",
        "        global author_ids\n",
        "       # print(next_author_id)\n",
        "        if author not in author_ids:\n",
        "            author_ids[author] = next_author_id\n",
        "            next_author_id += 1\n",
        "        return author_ids[author]\n",
        "        \n",
        "    with open(source_file_name.rstrip('clean_names.csv')+'_pub_graph.csv', 'w', newline='') as target_file: \n",
        "            writer = csv.writer(target_file)\n",
        "            header = ['author ID 1', 'author ID 2', 'author 1', 'author 2', 'year']\n",
        "            writer.writerow(header)   \n",
        "            for row in reader:\n",
        "                row_clean = row[authors_column].strip(\"[']\")\n",
        "                authors = row_clean.split(\"', '\")\n",
        "                year = row[year_column]\n",
        "                for i in range(len(authors)):\n",
        "                    for j in range(i, len(authors)):\n",
        "                        writer.writerow([author_id(authors[i]), author_id(authors[j]), authors[i], authors[j], year])\n",
        "\n",
        "    print('done')\n",
        "    #last step: calculating components, and the share of the biggest component, is done with connected.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36568038-52a4-4484-80b8-562a130be233",
      "metadata": {},
      "source": [
        "For 5.6: Sort papers by methods:\n",
        "Step 1: consolidate Abstracts and Auto Keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c8853e-1034-4448-b88b-518d21085f47",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "source_file_name = 'Titel Abtract Countries_fixed.csv'\n",
        "keyword_file_name_1 = 'Auto Keywords.csv'\n",
        "with open(source_file_name, 'r') as source_file: #master file for data \n",
        "    reader = csv.reader(source_file, delimiter = ',') \n",
        "    header = next(reader)\n",
        "    print(header)\n",
        "    set_column_name(title_column, 0, 'title')\n",
        "    set_column_name(uid_column, 3, 'uid')\n",
        "    set_column_name(year_column, 6, 'year')\n",
        "    set_column_name(abstract_column, 9, 'abstract')\n",
        "    set_column_name(country_count_column, 12, 'countryCount')\n",
        "    set_column_name(countries_column, 15, 'countryList')\n",
        "    with open(keyword_file_name_1, 'r') as source_file_KW: #additional file with keywords\n",
        "        reader2 = csv.reader(source_file_KW, delimiter = '\"') \n",
        "        header2 = next(reader2)\n",
        "        print(header2)\n",
        "        KW_uid_column = 1\n",
        "        if header2[KW_uid_column] != 'uid':\n",
        "            print('Error at \"KW publication ID\" column number')\n",
        "            sys.exit # evtl Luft nach oben bei dem Befehl hier\n",
        "        KW_year_column = 3\n",
        "        if header2[KW_year_column] != 'year':\n",
        "            print('Error at \"KW year\" column number')\n",
        "            sys.exit # evtl Luft nach oben bei dem Befehl hier\n",
        "        KW_tags_column = 5\n",
        "        if header2[KW_tags_column] != 'autotagList':\n",
        "            print('Error at \"KW tags\" column number')\n",
        "            sys.exit # evtl Luft nach oben bei dem Befehl hier\n",
        "        data_KW = {}\n",
        "        for row in reader2:\n",
        "            uid_KW = row[KW_uid_column]\n",
        "            if uid_KW not in data_KW:\n",
        "                data_KW[uid_KW] = [row]\n",
        "            else: \n",
        "                data_KW[uid_KW].append(row) #KW data sorted by uid\n",
        "        with open(source_file_name.rstrip('.csv')+'_KW.csv', 'w', newline='') as target_file: #new write file for consolidated data\n",
        "            writer = csv.writer(target_file)\n",
        "            header_w = ['UID', 'Title', 'Year', 'Abstract', 'Auto Keywords', 'Country Count', 'Country List']\n",
        "            writer.writerow(header_w)\n",
        "            for row in reader: #take each article in the master data set\n",
        "                year = row[year_column]\n",
        "                uid = row[uid_column]\n",
        "                title = row[title_column]\n",
        "                abstract = row[abstract_column]\n",
        "                country_count = row[country_count_column]\n",
        "                countries = row[countries_column]\n",
        "                if uid in data_KW:\n",
        "                    for row in data_KW[uid]: #find same uid in KW data set\n",
        "                        if row[KW_year_column] != year: #check for inconsistencies\n",
        "                            print('Years not matching for UID', uid)\n",
        "                            sys.exit # evtl Luft nach oben bei dem Befehl hier\n",
        "                        if len(row) >=6 and len(row[KW_tags_column]) > 0:\n",
        "                            KW_list = row[KW_tags_column]#.split('|') #if keywords exist, split the string into single keywords\n",
        "                            writer.writerow([uid, title, year, abstract, KW_list, country_count, countries])\n",
        "                        else:\n",
        "                           writer.writerow([uid, title, year, abstract, '', country_count, countries]) \n",
        "                else:\n",
        "                    writer.writerow([uid, title, year, abstract, '', country_count, countries])\n",
        "                    print('no UID match in auto KW data for UID', uid)\n",
        "print('Done')\n",
        "                    \n",
        "            \n",
        "                \n",
        "                \n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8613227-f5b3-47d0-a752-99ada95356d8",
      "metadata": {},
      "source": [
        "For 5.6 Step 2:\n",
        "Consolidate Abstracts, Auto KWs, and Manual KWs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c3b8977-375f-431e-9639-f8fb3c24ac71",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "source_file_name = 'Titel Abtract Countries_fixed_KW.csv'\n",
        "keyword_file_name = 'Manual Keywords.csv'\n",
        "with open(source_file_name, 'r') as source_file: #master file for data \n",
        "    reader = csv.reader(source_file, delimiter = ',') \n",
        "    header = next(reader)\n",
        "    print(header)\n",
        "    set_column_name(title_column, 1, 'Title')\n",
        "    set_column_name(uid_column, 0, 'UID')\n",
        "    set_column_name(year_column, 2, 'Year')\n",
        "    set_column_name(abstract_column, 3, 'Abstract')\n",
        "    set_column_name(auto_KW_column, 4, 'Auto Keywords')\n",
        "    set_column_name(country_count_column, 5, 'Country Count')\n",
        "    set_column_name(countries_column, 6, 'Country List')\n",
        "    with open(keyword_file_name, 'r') as source_file_KW: #additional file with keywords\n",
        "        reader2 = csv.reader(source_file_KW, delimiter = '\"') \n",
        "        header2 = next(reader2)\n",
        "        print(header2)\n",
        "        set_column_name(KW_uid_column, 1, 'uid')\n",
        "        set_column_name(KW_year_column, 3, 'year')\n",
        "        set_column_name(KW_tags_column, 5, 'manualtagList')\n",
        "        data_KW = {}\n",
        "        for row in reader2:\n",
        "            uid_KW = row[KW_uid_column]\n",
        "            if uid_KW not in data_KW:\n",
        "                data_KW[uid_KW] = [row]\n",
        "            else: \n",
        "                data_KW[uid_KW].append(row) #KW data sorted by uid\n",
        "        with open(source_file_name.rstrip('.csv')+'_all.csv', 'w', newline='') as target_file: #new write file for consolidated data\n",
        "            writer = csv.writer(target_file)\n",
        "            header_w = ['UID', 'Title', 'Year', 'Abstract', 'Auto Keywords', 'Manual Keywords','Country Count', 'Country List']\n",
        "            writer.writerow(header_w)\n",
        "            for row in reader: #take each article in the master data set\n",
        "                year = row[year_column]\n",
        "                uid = row[uid_column]\n",
        "                title = row[title_column]\n",
        "                abstract = row[abstract_column]\n",
        "                auto_KW_list = row[auto_KW_column]\n",
        "                country_count = row[country_count_column]\n",
        "                countries = row[countries_column]\n",
        "                if uid in data_KW:\n",
        "                    for row in data_KW[uid]: #find same uid in KW data set\n",
        "                        if row[KW_year_column] != year:  #check for inconsistencies\n",
        "                            print('Years not matching for UID', uid)\n",
        "                            sys.exit # evtl Luft nach oben bei dem Befehl hier\n",
        "                        if len(row) >=6 and len(row[KW_tags_column]) > 0:\n",
        "                            man_KW_list = row[KW_tags_column]#.split('|') #if keywords exist, split the string into single keywords\n",
        "                            writer.writerow([uid, title, year, abstract, auto_KW_list, man_KW_list, country_count, countries])\n",
        "                        else:\n",
        "                           writer.writerow([uid, title, year, abstract,auto_KW_list, '', country_count, countries]) \n",
        "                else:\n",
        "                    writer.writerow([uid, title, year, abstract, auto_KW_list,'', country_count, countries])\n",
        "                    print('no UID match in manual KW data for UID', uid)\n",
        "print('Done')\n",
        "                    \n",
        "            \n",
        "                \n",
        "                \n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "429a31de-082f-4a98-a77c-82cd6374f321",
      "metadata": {},
      "source": [
        "For 5.6 Step 3:\n",
        "Search all three fields for mentions of certain methods "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d24964e6-e564-4fda-a36b-fda78cd43d81",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "source_file_name = 'Titel Abtract Countries_fixed_KW_all.csv'\n",
        "with open(source_file_name, 'r') as source_file: \n",
        "    reader = csv.reader(source_file, delimiter = ',') \n",
        "    header = next(reader)\n",
        "    prsource_file_name = 'Titel Abtract Countries_fixed_KW_all.csv'\n",
        "with open(source_file_name, 'r') as source_file: \n",
        "    reader = csv.reader(source_file, delimiter = ',') \n",
        "    header = next(reader)\n",
        "    print(header)\n",
        "    set_column_name(uid_column, 0, 'UID')\n",
        "    set_column_name(title_column, 1, 'Title')\n",
        "    set_column_name(year_column, 2, 'Year')\n",
        "    set_column_name(abstract_column, 3, 'Abstract')\n",
        "    set_column_name(KW_auto_column, 4, 'Auto Keywords')\n",
        "    set_column_name(KW_manual_column, 4, 'Manual Keywords')\n",
        "    data = {}\n",
        "    for row in reader:\n",
        "            year = row[year_column]\n",
        "            if year not in data:\n",
        "                data[year] = [row]\n",
        "            else: \n",
        "                data[year].append(row) #data sorted by year\n",
        "    with open('Methods_2.csv', 'w', newline='') as target_file: \n",
        "        writer = csv.writer(target_file)\n",
        "        method_list = ['participat', 'creative', 'qualitative', 'quantitative', 'backcasting', 'brainstorming',  'citizen panel', 'conference', 'workshop', 'essay', 'expert panel', 'genius forecast', 'interview', 'literature review', 'morphological analysis',  'relevance tree', 'logic chart', 'logic diagram', 'role play', 'acting', 'scanning' , 'scenario workshop', 'science fictioning', 'simulation gaming', 'surveys', 'swot analysis', 'wildcard', 'benchmarking', 'bibliometrics', 'indicator',  'time series',  'modelling', 'patent analysis', 'extrapolation',  'cross-impact analysis',  'structural analysis', 'delphi', 'key technolog', 'critical technolog', 'multi-criteria', 'polling', 'voting', 'quantitative scenario', 'SMIC', 'roadmapping', 'stakeholder analysis', 'scenario', 'futures workshop']\n",
        "        header_w = ['Year', '# Publications with Data']+method_list\n",
        "        writer.writerow(header_w)\n",
        "        for year in data:\n",
        "            counter = {}\n",
        "            for method in method_list:\n",
        "                counter[method] = 0\n",
        "                counter_pubs = 0\n",
        "                for row in data[year]:\n",
        "                    search_space = row[title_column]+row[abstract_column]+row[KW_auto_column]+row[KW_manual_column]\n",
        "                   # print(search_space)\n",
        "                    if method in search_space.lower():\n",
        "                        counter[method] += 1\n",
        "                    if len(search_space) > 0:\n",
        "                        counter_pubs += 1\n",
        "            writer.writerow([year, counter_pubs]+[counter[method] for method in method_list])\n",
        "                       \n",
        "print('Done')\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
