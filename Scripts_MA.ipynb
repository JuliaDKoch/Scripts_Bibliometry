{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "aa47569c-2e88-4112-be3f-a3a6cbc1cfaa",
      "cell_type": "code",
      "source": "# setup: \nimport csv #for CSV handling\nimport re #for regular expressions handling",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "330f821a-a988-4299-bd62-5258d92a70a5",
      "cell_type": "code",
      "source": "# check whether columns have the right title, if so, name them for easier handling \ndef set_column_name(column_name, column_number, column_title):\n    if header[column_number] != column_title:\n        print('Error at', column_name,  'column number')\n        sys.exit(1) # evtl Luft nach oben bei dem Befehl hier\n    else: column_name = column_number",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7a4d441d-1733-491d-9f58-36d9b98f4311",
      "cell_type": "raw",
      "source": "For 5.5: Process KATI data on Internationality, Step 1: calculate for each year and each number of countries how many single/multiple author papers there are with this number of countries involved",
      "metadata": {}
    },
    {
      "id": "508c10f0-dee3-4d00-8daf-d2f4dc5cf935",
      "cell_type": "code",
      "source": "source_file_name = '.csv'  #input are \"Internationality\" files which have been brought to CSV format without \" manually\nwith open(source_file_name, 'r') as source_file:\n    reader = csv.reader(source_file, delimiter = ';')\n    header = next(reader)\n    print(header)\n    set_column_name(year_column, 1, 'year')\n    set_column_name(number_countries_column, 4, 'countryCount')\n    set_column_name(number_authors_column, 2, 'Nauthor')\n    data = {}     #sort data by year and make it accessible by year\n    for row in reader:\n        year = row[year_column]\n        if year not in data:\n            data[year] = [row]\n        else: \n            data[year].append(row)\n    with open(source_file_name.rstrip('.csv')+'_country_numbers_raw.csv', 'w', newline='') as target_file:\n        writer = csv.writer(target_file)\n        header = ['year', '#countries', 'document count single author', 'document count multiple authors']\n        writer.writerow(header)\n        for year in data:\n            max_num_countries = max(int(row[number_countries_column]) for row in data[year])\n            print (year, '   ', max_num_countries) #for plausibility check while running\n            for this_num_countries in range(0,max_num_countries+1): \n                counter_this_num_countries_single_author = 0 #count single-author papers seperately\n                counter_this_num_countries_multiple_authors = 0\n                for row in data[year]:\n                    if int(row[number_countries_column]) == this_num_countries:\n                        if int(row[number_authors_column]) == 1:\n                            counter_this_num_countries_single_author += 1 \n                        else:\n                            counter_this_num_countries_multiple_authors += 1\n                writer.writerow([year, this_num_countries, counter_this_num_countries_single_author, counter_this_num_countries_multiple_authors])\n                \nprint('done')",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "['UID', 'year', 'Nauthor', 'Naddress', 'countryCount', 'countryList', ' ,']\n1998     4\n2000     4\n2022     11\n2011     37\n2004     4\n2003     4\n2024     6\n2005     5\n2010     5\n2002     4\n2009     4\n1999     4\n1996     4\n2012     39\n2008     5\n1992     3\n2016     6\n2018     46\n1994     6\n2007     5\n2025     5\n2019     5\n2001     21\n1997     4\n2015     44\n2021     6\n2023     5\n2006     4\n2020     7\n1991     3\n2017     44\n1990     3\n1987     2\n2013     38\n2014     4\n1995     3\n1988     3\n1989     3\n1986     2\n1993     14\n1984     1\n1985     2\ndone\n"
        }
      ],
      "execution_count": 16
    },
    {
      "id": "c384805f-f573-4f94-afeb-c3d7165fc790",
      "cell_type": "raw",
      "source": "For 5.5.: Step 2: aggregate into clusters of numbers and return maximal number of countries per year",
      "metadata": {}
    },
    {
      "id": "3d561040-a380-4adf-9cfd-a8a4301c2a04",
      "cell_type": "code",
      "source": "source_file_name = ''  #input are \"Internationality\" files which have been brought to CSV format without \" manually\nwith open(source_file_name, 'r') as source_file:\n    reader = csv.reader(source_file, delimiter = ';')\n    header = next(reader)\n    print(header)\n    set_column_name(year_column, 1, 'year')\n    set_column_name(number_countries_column, 4, 'countryCount')\n    set_column_name(number_authors_column, 2, 'Nauthor')\n    data = {}\n    for row in reader:\n        year = row[year_column]\n        if year not in data:\n            data[year] = [row]\n        else: \n            data[year].append(row)\n    with open(source_file_name.rstrip('.csv')+'_country_numbers_aggr.csv', 'w', newline='') as target_file:\n        writer = csv.writer(target_file)\n        header = ['year', '#:0country', '#:1country1author', '#:1country_more_authors', '#:2countries', '#:3-5countries', '#:6-10countries','#:>=11countries', 'max # of countries']\n        writer.writerow(header)\n        for year in data:\n            max_num_countries = max(int(row[number_countries_column]) for row in data[year])\n            print (year, '   ', max_num_countries)\n            counter_no_country = 0\n            counter_1_country_1_author = 0\n            counter_1_country_more_authors = 0\n            counter_2_countries = 0\n            counter_3_to_5_countries = 0\n            counter_6_to_10_countries = 0\n            counter_many_countries = 0\n            for this_num_countries in range(0,max_num_countries+1):\n                counter_this_num_countries_single_author = 0\n                counter_this_num_countries_multiple_authors = 0\n                temp_count_3_to_5 = 0\n                temp_count_6_to_10 = 0\n                temp_count_many = 0\n                for row in data[year]:\n                    if int(row[number_countries_column]) == this_num_countries:\n                            if int(row[number_authors_column]) == 1:\n                                counter_this_num_countries_single_author += 1 \n                            else:\n                                counter_this_num_countries_multiple_authors += 1\n                if this_num_countries == 0:\n                   counter_no_country = counter_this_num_countries_single_author + counter_this_num_countries_multiple_authors\n                else:\n                    if this_num_countries == 1:\n                       counter_1_country_1_author = counter_this_num_countries_single_author\n                       counter_1_country_more_authors = counter_this_num_countries_multiple_authors\n                    else:\n                        if this_num_countries == 2:\n                            counter_2_countries = counter_this_num_countries_single_author + counter_this_num_countries_multiple_authors\n                        else:\n                            if 3 <= this_num_countries <= 5:\n                               temp_count_3_to_5 = counter_this_num_countries_single_author + counter_this_num_countries_multiple_authors\n                            else:\n                                if 6 <= this_num_countries <= 10:\n                                   counter_6_to_10_countries = counter_this_num_countries_single_author + counter_this_num_countries_multiple_authors\n                                else:\n                                     temp_count_many = counter_this_num_countries_single_author + counter_this_num_countries_multiple_authors\n                counter_3_to_5_countries += temp_count_3_to_5 \n                counter_6_to_10_countries += temp_count_6_to_10\n                counter_many_countries += temp_count_many\n            writer.writerow([year, counter_no_country,counter_1_country_1_author, counter_1_country_more_authors, counter_2_countries, counter_3_to_5_countries, counter_6_to_10_countries, counter_many_countries, max_num_countries])\n    \nprint('done')\n#final grouping into single author, national, international was done directly in Excel",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "['UID', 'year', 'Nauthor', 'Naddress', 'countryCount', 'countryList', ' ']\n2018     7\n2013     6\n2022     9\n1999     5\n1998     5\n2007     6\n2015     7\n2009     5\n2001     5\n2014     8\n2002     5\n2012     12\n2010     6\n2016     7\n1997     4\n2019     15\n2000     7\n2008     9\n2024     10\n2006     12\n2020     7\n2017     10\n1994     5\n2025     29\n1996     5\n2023     9\n2021     14\n2005     4\n2003     6\n2011     6\n2004     6\n1992     4\n1995     4\n1993     4\n1991     3\n1989     1\n2026     4\n1990     1\n1985     1\n1988     1\n1987     1\n1986     1\ndone\n"
        }
      ],
      "execution_count": 188
    },
    {
      "id": "2c14f0d4-9c2d-4586-af94-156d44f8ea44",
      "cell_type": "raw",
      "source": "For 5.2: Preprocess country data by clustering by periods; check for country name issues",
      "metadata": {}
    },
    {
      "id": "92f9a4b8-ec55-48d4-aef6-3ec996b60147",
      "cell_type": "code",
      "source": "source_file_name = 'Countries_List.csv'  \nwith open(source_file_name, 'r') as source_file:\n    reader = csv.reader(source_file, delimiter = '\"') #use \" as delimiter to avoid trouble with the commata in the names\n    header = next(reader)\n    print(header)\n    set_column_name(year_column, 1, 'year')\n    set_column_name(country_name_column, 3, 'countryLabel')\n    set_column_name(country_tag_column, 5, 'iso3')\n    set_column_name(pub_num_column, 7, 'N_pub')\n    set_column_name(continent_column, 11, 'continentLabel')\n    data = {}\n    for row in reader:\n        country_tag = row[country_tag_column]\n        if country_tag not in data:\n            data[country_tag] = [row]\n        else: \n            data[country_tag].append(row)\n    with open(source_file_name.rstrip('.csv')+'_aggr_periods.csv', 'w', newline='') as target_file:\n        writer = csv.writer(target_file)\n        header = ['Continent', 'Country Name', '#Publications 1970-1999', '#Publications 2000-2009', '#Publications 2010-2020', '#Publications 2020-2025']\n        writer.writerow(header)\n        for iso3 in data:\n            counter_to_1999 = 0\n            counter_2000_2009 = 0\n            counter_2010_2019 = 0\n            counter_from_2020 = 0\n            countryLabel = ''\n            continent = ''\n            for row in data[iso3]:\n                if countryLabel != str(row[country_name_column]) and countryLabel != '':\n                    print(iso3, ' has two names: ', countryLabel, ' and ', str(row[country_name_column])) #check if country names are ambiguous\n                if int(row[year_column]) <= 1999:\n                    counter_to_1999 += int(row[pub_num_column])\n                else:\n                    if 2000 <= int(row[year_column]) <= 2009:\n                        counter_2000_2009 += int(row[pub_num_column])\n                    else:\n                        if 2010 <= int(row[year_column]) <= 2019:\n                            counter_2010_2019 += int(row[pub_num_column])\n                        else: \n                             counter_from_2020 += int(row[pub_num_column])\n                countryLabel = str(row[country_name_column])\n                if str(row[continent_column]).endswith('america'):\n                    continent =  str(row[continent_column]).rstrip('america').capitalize() + ' America'\n                else: \n                    continent = str(row[continent_column]).capitalize()\n            writer.writerow([continent, countryLabel,counter_to_1999, counter_2000_2009, counter_2010_2019, counter_from_2020 ])\n  \n\nprint('done')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d4474fe6-d302-45cd-ad50-c13df07d0376",
      "cell_type": "raw",
      "source": "For 5.7 : Preprocess Country Data by collect DACH, UK, US data per year; as well as total number per year",
      "metadata": {}
    },
    {
      "id": "f4ae51ef-ddea-4ebd-95ee-c4632877b58d",
      "cell_type": "code",
      "source": "source_file_name = 'Countries_List.csv'  \nwith open(source_file_name, 'r') as source_file:\n    reader = csv.reader(source_file, delimiter = '\"') #use \" as delimiter to avoid trouble with the commata in the names\n    header = next(reader)\n    print(header)\n    set_column_name(year_column, 1, 'year')\n    set_column_name(country_name_column, 3, 'countryLabel')\n    set_column_name(country_tag_column, 5, 'iso3')\n    set_column_name(pub_num_column, 7, 'N_pub')\n    set_column_name(continent_column, 11, 'continentLabel')\n    data = {}\n    for row in reader:\n        year = row[year_column]\n        if year not in data:\n            data[year] = [row]\n        else: \n            data[year].append(row)\n    with open(source_file_name.rstrip('.csv')+'_DACH_UK_US_all.csv', 'w', newline='') as target_file:\n        writer = csv.writer(target_file)\n        header = ['Year', '#Pubs DACH', '#Pubs UK', '#Pubs US', '# all Pubs']\n        writer.writerow(header)\n        for year in data:\n            counter_DACH = 0\n            counter_UK = 0\n            counter_US = 0\n            counter_all = 0\n            for row in data[year]:\n                iso3 = row[country_tag_column]\n                counter_all += int(row[pub_num_column])\n                if iso3 == 'deu' or iso3 == 'aut' or iso3 == 'che':\n                    counter_DACH += int(row[pub_num_column])\n                if iso3 == 'gbr':\n                    counter_UK += int(row[pub_num_column])\n                if iso3 == 'usa':\n                    counter_US += int(row[pub_num_column])\n \n            #print(iso3, ' ', counter_to_1999, counter_2000_2009, counter_2010_2019, counter_from_2020)\n            writer.writerow([year, counter_DACH, counter_UK, counter_US, counter_all])\nprint('done')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9830ccf6-8fee-441c-ad85-ec469f9c9662",
      "cell_type": "raw",
      "source": "For 5.4: Clean name data in co-publication files by bringing all names to 'Last name, Initial' format:",
      "metadata": {}
    },
    {
      "id": "2d110c11-eb5a-4a8e-bf2d-fac85b16636d",
      "cell_type": "code",
      "source": "source_file_name = 'Koauthor List Fullerene.csv'  \nwith open(source_file_name, 'r') as source_file:\n    reader = csv.reader(source_file, delimiter = '\"') # use \" (around all strings in the source file) as the read-delimiter to avoid trouble with the commata in the names\n    header = next(reader)\n    print(header)\n    set_column_name(ID_column, 1, 'uid')\n    set_column_name(year_column, 3, 'year')\n    set_column_name(names_column, 5, 'author_list')\n    with open(source_file_name.rstrip('.csv')+'_clean_names.csv', 'w', newline='') as target_file: # \"intermediate\" file for QA purposes\n            writer = csv.writer(target_file)\n            header = ['ID', 'year', 'authors']\n            writer.writerow(header)\n            for row in reader: \n                #if len(row) >= 6: \n                    authors_list = []\n                    name = str(row[names_column]).title()\n                    # bring all names to format with capitalised first letter, rest in lower case\n                    names_list = name.split('|')\n                    # split at '|‘ (delimiter between different author names) \n                    for name in names_list:\n                        name_split = [string.strip() for string in name.split(',')]\n                        # split each name at comma between last name and first names, and remove all leading/trailing white spaces\n                        if len(name_split) > 1: \n                            name_clean = name_split[0] + ', ' + name_split[1][0]\n                        else: \n                            name_clean = name_split[0] + ', ' \n                        # cleaned name is of format [last name], [first initial], unless no info about first name(s) is given; name format in this case is [last name], [blank]\n                        if name_clean not in authors_list:\n                            authors_list.append(name_clean)\n                            # add cleaned name to authors' list unless it is already there\n                    ID = row[ID_column]\n                    year = row[year_column]\n                    writer.writerow([ID, year, authors_list])\nprint('Done')\n# POTENTIAL IMPROVEMENT: catch different spellings of last names (Müller vs Mueller etc.)\n   \n    \n   ",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[' ', 'uid', ' , ', 'year', ' , ', 'author_list', ' ,']\nDone\n"
        }
      ],
      "execution_count": 14
    },
    {
      "id": "3cd737e5-527a-42cf-b800-de03730d0452",
      "cell_type": "raw",
      "source": "For 5.4: Create list of co-publication graph edges ",
      "metadata": {}
    },
    {
      "id": "a8946ea3-c7da-437f-b587-8dbe6001696a",
      "cell_type": "code",
      "source": "source_file_name = 'Koauthor List Fullerene_clean_names.csv'  \nwith open(source_file_name, 'r') as source_file:\n    reader = csv.reader(source_file, delimiter = ',') \n    header = next(reader)\n    print(header)\n    set_column_name(authors_column, 2, 'authors')\n    set_column_name(year_column, 1, 'year')\n    next_author_id = 0 \n    author_ids = {}\n    def author_id(author):\n        global next_author_id\n        global author_ids\n       # print(next_author_id)\n        if author not in author_ids:\n            author_ids[author] = next_author_id\n            next_author_id += 1\n        return author_ids[author]\n        \n    with open(source_file_name.rstrip('clean_names.csv')+'_pub_graph.csv', 'w', newline='') as target_file: \n            writer = csv.writer(target_file)\n            header = ['author ID 1', 'author ID 2', 'author 1', 'author 2', 'year']\n            writer.writerow(header)   \n            for row in reader:\n                row_clean = row[authors_column].strip(\"[']\")\n                authors = row_clean.split(\"', '\")\n                year = row[year_column]\n                for i in range(len(authors)):\n                    for j in range(i, len(authors)):\n                        writer.writerow([author_id(authors[i]), author_id(authors[j]), authors[i], authors[j], year])\n\n    print('done')\n    #last step: calculating components, and the share of the biggest component, is done with connected.py\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "['ID', 'year', 'authors']\ndone\n"
        }
      ],
      "execution_count": 15
    },
    {
      "id": "36568038-52a4-4484-80b8-562a130be233",
      "cell_type": "raw",
      "source": "For 5.6: Sort papers by methods:\nStep 1: consolidate Abstracts and Auto Keywords",
      "metadata": {}
    },
    {
      "id": "b4c8853e-1034-4448-b88b-518d21085f47",
      "cell_type": "code",
      "source": "source_file_name = 'Titel Abtract Countries_fixed.csv'\nkeyword_file_name_1 = 'Auto Keywords.csv'\nwith open(source_file_name, 'r') as source_file: #master file for data \n    reader = csv.reader(source_file, delimiter = ',') \n    header = next(reader)\n    print(header)\n    title_column = 0\n    if header[title_column] != 'title':\n        print('Error at \"title\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    uid_column = 3\n    if header[uid_column] != 'uid':\n        print('Error at \"publication ID\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    year_column = 6\n    if header[year_column] != 'year':\n        print('Error at \"year\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    abstract_column = 9\n    if header[abstract_column] != 'abstract':\n        print('Error at \"abstract\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    country_count_column = 12\n    if header[country_count_column] != 'countryCount':\n        print('Error at \"#countries\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    countries_column = 15\n    if header[countries_column] != 'countryList':\n        print('Error at \"Countries\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    with open(keyword_file_name_1, 'r') as source_file_KW: #additional file with keywords\n        reader2 = csv.reader(source_file_KW, delimiter = '\"') \n        header2 = next(reader2)\n        print(header2)\n        KW_uid_column = 1\n        if header2[KW_uid_column] != 'uid':\n            print('Error at \"KW publication ID\" column number')\n            sys.exit # evtl Luft nach oben bei dem Befehl hier\n        KW_year_column = 3\n        if header2[KW_year_column] != 'year':\n            print('Error at \"KW year\" column number')\n            sys.exit # evtl Luft nach oben bei dem Befehl hier\n        KW_tags_column = 5\n        if header2[KW_tags_column] != 'autotagList':\n            print('Error at \"KW tags\" column number')\n            sys.exit # evtl Luft nach oben bei dem Befehl hier\n        data_KW = {}\n        for row in reader2:\n            uid_KW = row[KW_uid_column]\n            if uid_KW not in data_KW:\n                data_KW[uid_KW] = [row]\n            else: \n                data_KW[uid_KW].append(row) #KW data sorted by uid\n        with open(source_file_name.rstrip('.csv')+'_KW.csv', 'w', newline='') as target_file: #new write file for consolidated data\n            writer = csv.writer(target_file)\n            header_w = ['UID', 'Title', 'Year', 'Abstract', 'Auto Keywords', 'Country Count', 'Country List']\n            writer.writerow(header_w)\n            for row in reader: #take each article in the master data set\n                year = row[year_column]\n                uid = row[uid_column]\n                title = row[title_column]\n                abstract = row[abstract_column]\n                country_count = row[country_count_column]\n                countries = row[countries_column]\n                if uid in data_KW:\n                    for row in data_KW[uid]: #find same uid in KW data set\n                        if row[KW_year_column] != year: #check for inconsistencies\n                            print('Years not matching for UID', uid)\n                            sys.exit # evtl Luft nach oben bei dem Befehl hier\n                        if len(row) >=6 and len(row[KW_tags_column]) > 0:\n                            KW_list = row[KW_tags_column]#.split('|') #if keywords exist, split the string into single keywords\n                            writer.writerow([uid, title, year, abstract, KW_list, country_count, countries])\n                        else:\n                           writer.writerow([uid, title, year, abstract, '', country_count, countries]) \n                else:\n                    writer.writerow([uid, title, year, abstract, '', country_count, countries])\n                    print('no UID match in auto KW data for UID', uid)\nprint('Done')\n                    \n            \n                \n                \n        \n        ",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "['title', '', '', 'uid', '', '', 'year', '', '', 'abstract', '', '', 'countryCount', '', '', 'countryList']\n[' ', 'uid', ' , ', 'year', ' , ', 'autotagList', ' ,']\nDone\n"
        }
      ],
      "execution_count": 149
    },
    {
      "id": "c8613227-f5b3-47d0-a752-99ada95356d8",
      "cell_type": "raw",
      "source": "For 5.6 Step 2:\nConsolidate Abstracts, Auto KWs, and Manual KWs:",
      "metadata": {}
    },
    {
      "id": "0c3b8977-375f-431e-9639-f8fb3c24ac71",
      "cell_type": "code",
      "source": "source_file_name = 'Titel Abtract Countries_fixed_KW.csv'\nkeyword_file_name = 'Manual Keywords.csv'\nwith open(source_file_name, 'r') as source_file: #master file for data \n    reader = csv.reader(source_file, delimiter = ',') \n    header = next(reader)\n    print(header)\n    title_column = 1\n    if header[title_column] != 'Title':\n        print('Error at \"title\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    uid_column = 0\n    if header[uid_column] != 'UID':\n        print('Error at \"publication ID\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    year_column = 2\n    if header[year_column] != 'Year':\n        print('Error at \"year\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    abstract_column = 3\n    if header[abstract_column] != 'Abstract':\n        print('Error at \"abstract\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    auto_KW_column = 4\n    if header[auto_KW_column] != 'Auto Keywords':\n        print('Error at \"auto KW\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    country_count_column = 5\n    if header[country_count_column] != 'Country Count':\n        print('Error at \"Country Count\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    countries_column = 6\n    if header[countries_column] != 'Country List':\n        print('Error at \"Countries\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    with open(keyword_file_name, 'r') as source_file_KW: #additional file with keywords\n        reader2 = csv.reader(source_file_KW, delimiter = '\"') \n        header2 = next(reader2)\n        print(header2)\n        KW_uid_column = 1\n        if header2[KW_uid_column] != 'uid':\n            print('Error at \"KW publication ID\" column number')\n            sys.exit # evtl Luft nach oben bei dem Befehl hier\n        KW_year_column = 3\n        if header2[KW_year_column] != 'year':\n            print('Error at \"KW year\" column number')\n            sys.exit # evtl Luft nach oben bei dem Befehl hier\n        KW_tags_column = 5\n        if header2[KW_tags_column] != 'manualtagList':\n            print('Error at \"KW tags\" column number')\n            sys.exit # evtl Luft nach oben bei dem Befehl hier\n        data_KW = {}\n        for row in reader2:\n            uid_KW = row[KW_uid_column]\n            if uid_KW not in data_KW:\n                data_KW[uid_KW] = [row]\n            else: \n                data_KW[uid_KW].append(row) #KW data sorted by uid\n        with open(source_file_name.rstrip('.csv')+'_all.csv', 'w', newline='') as target_file: #new write file for consolidated data\n            writer = csv.writer(target_file)\n            header_w = ['UID', 'Title', 'Year', 'Abstract', 'Auto Keywords', 'Manual Keywords','Country Count', 'Country List']\n            writer.writerow(header_w)\n            for row in reader: #take each article in the master data set\n                year = row[year_column]\n                uid = row[uid_column]\n                title = row[title_column]\n                abstract = row[abstract_column]\n                auto_KW_list = row[auto_KW_column]\n                country_count = row[country_count_column]\n                countries = row[countries_column]\n                if uid in data_KW:\n                    for row in data_KW[uid]: #find same uid in KW data set\n                        if row[KW_year_column] != year:  #check for inconsistencies\n                            print('Years not matching for UID', uid)\n                            sys.exit # evtl Luft nach oben bei dem Befehl hier\n                        if len(row) >=6 and len(row[KW_tags_column]) > 0:\n                            man_KW_list = row[KW_tags_column]#.split('|') #if keywords exist, split the string into single keywords\n                            writer.writerow([uid, title, year, abstract, auto_KW_list, man_KW_list, country_count, countries])\n                        else:\n                           writer.writerow([uid, title, year, abstract,auto_KW_list, '', country_count, countries]) \n                else:\n                    writer.writerow([uid, title, year, abstract, auto_KW_list,'', country_count, countries])\n                    print('no UID match in manual KW data for UID', uid)\nprint('Done')\n                    \n            \n                \n                \n        \n        ",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "['UID', 'Title', 'Year', 'Abstract', 'Auto Keywords', 'Country Count', 'Country List']\n[' ', 'uid', ' , ', 'year', ' , ', 'manualtagList', ' ,']\nDone\n"
        }
      ],
      "execution_count": 150
    },
    {
      "id": "429a31de-082f-4a98-a77c-82cd6374f321",
      "cell_type": "raw",
      "source": "For 5.6 Step 3:\nSearch all three fields for mentions of certain methods ",
      "metadata": {}
    },
    {
      "id": "d24964e6-e564-4fda-a36b-fda78cd43d81",
      "cell_type": "code",
      "source": "source_file_name = 'Titel Abtract Countries_fixed_KW_all.csv'\nwith open(source_file_name, 'r') as source_file: \n    reader = csv.reader(source_file, delimiter = ',') \n    header = next(reader)\n    prsource_file_name = 'Titel Abtract Countries_fixed_KW_all.csv'\nwith open(source_file_name, 'r') as source_file: \n    reader = csv.reader(source_file, delimiter = ',') \n    header = next(reader)\n    print(header)\n    uid_column = 0\n    check_column_name(uid_column,'UID')\n    title_column = 1\n    check_column_name(title_column,'Title')\n    year_column = 2\n    check_column_name(year_column,'Year')\n    abstract_column = 3\n    check_column_name(abstract_column,'Abstract')\n\n    KW_auto_column = 4\n    if header[KW_auto_column] != 'Auto Keywords':\n        print('Error at \"Auto KW\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    KW_manual_column = 5\n    if header[KW_manual_column] != 'Manual Keywords':\n        print('Error at \"Manual KW\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    data = {}\n    for row in reader:\n            year = row[year_column]\n            if year not in data:\n                data[year] = [row]\n            else: \n                data[year].append(row) #data sorted by year\n    with open('Methods_2.csv', 'w', newline='') as target_file: \n        writer = csv.writer(target_file)\n        method_list = ['participat', 'creative', 'qualitative', 'quantitative', 'backcasting', 'brainstorming',  'citizen panel', 'conference', 'workshop', 'essay', 'expert panel', 'genius forecast', 'interview', 'literature review', 'morphological analysis',  'relevance tree', 'logic chart', 'logic diagram', 'role play', 'acting', 'scanning' , 'scenario workshop', 'science fictioning', 'simulation gaming', 'surveys', 'swot analysis', 'wildcard', 'benchmarking', 'bibliometrics', 'indicator',  'time series',  'modelling', 'patent analysis', 'extrapolation',  'cross-impact analysis',  'structural analysis', 'delphi', 'key technolog', 'critical technolog', 'multi-criteria', 'polling', 'voting', 'quantitative scenario', 'SMIC', 'roadmapping', 'stakeholder analysis', 'scenario', 'futures workshop']\n        header_w = ['Year', '# Publications with Data']+method_list\n        writer.writerow(header_w)\n        for year in data:\n            counter = {}\n            for method in method_list:\n                counter[method] = 0\n                counter_pubs = 0\n                for row in data[year]:\n                    search_space = row[title_column]+row[abstract_column]+row[KW_auto_column]+row[KW_manual_column]\n                   # print(search_space)\n                    if method in search_space.lower():\n                        counter[method] += 1\n                    if len(search_space) > 0:\n                        counter_pubs += 1\n            writer.writerow([year, counter_pubs]+[counter[method] for method in method_list])\n                       \nprint('Done')\n    source_file_name = 'Titel Abtract Countries_fixed_KW_all.csv'\nwith open(source_file_name, 'r') as source_file: \n    reader = csv.reader(source_file, delimiter = ',') \n    header = next(reader)\n    print(header)\n    uid_column = 0\n    check_column_name(uid_column,'UID')\n    title_column = 1\n    check_column_name(title_column,'Title')\n    year_column = 2\n    check_column_name(year_column,'Year')\n    abstract_column = 3\n    check_column_name(abstract_column,'Abstract')\n\n    KW_auto_column = 4\n    if header[KW_auto_column] != 'Auto Keywords':\n        print('Error at \"Auto KW\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    KW_manual_column = 5\n    if header[KW_manual_column] != 'Manual Keywords':\n        print('Error at \"Manual KW\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    data = {}\n    for row in reader:\n            year = row[year_column]\n            if year not in data:\n                data[year] = [row]\n            else: \n                data[year].append(row) #data sorted by year\n    with open('Methods_2.csv', 'w', newline='') as target_file: \n        writer = csv.writer(target_file)\n        method_list = ['participat', 'creative', 'qualitative', 'quantitative', 'backcasting', 'brainstorming',  'citizen panel', 'conference', 'workshop', 'essay', 'expert panel', 'genius forecast', 'interview', 'literature review', 'morphological analysis',  'relevance tree', 'logic chart', 'logic diagram', 'role play', 'acting', 'scanning' , 'scenario workshop', 'science fictioning', 'simulation gaming', 'surveys', 'swot analysis', 'wildcard', 'benchmarking', 'bibliometrics', 'indicator',  'time series',  'modelling', 'patent analysis', 'extrapolation',  'cross-impact analysis',  'structural analysis', 'delphi', 'key technolog', 'critical technolog', 'multi-criteria', 'polling', 'voting', 'quantitative scenario', 'SMIC', 'roadmapping', 'stakeholder analysis', 'scenario', 'futures workshop']\n        header_w = ['Year', '# Publications with Data']+method_list\n        writer.writerow(header_w)\n        for year in data:\n            counter = {}\n            for method in method_list:\n                counter[method] = 0\n                counter_pubs = 0\n                for row in data[year]:\n                    search_space = row[title_column]+row[abstract_column]+row[KW_auto_column]+row[KW_manual_column]\n                   # print(search_space)\n                    if method in search_space.lower():\n                        counter[method] += 1\n                    if len(search_space) > 0:\n                        counter_pubs += 1\n            writer.writerow([year, counter_pubs]+[counter[method] for method in method_list])\n                       \nprint('Done')\n    int(header)\n    uid_column = 0\n    check_column_name(uid_column,'UID')\n    title_column = 1\n    check_column_name(title_column,'Title')\n    year_column = 2\n    check_column_name(year_column,'Year')\n    abstract_column = 3\n    check_column_name(abstract_column,'Abstract')\n\n    KW_auto_column = 4\n    if header[KW_auto_column] != 'Auto Keywords':\n        print('Error at \"Auto KW\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    KW_manual_column = 5\n    if header[KW_manual_column] != 'Manual Keywords':\n        print('Error at \"Manual KW\" column number')\n        sys.exit # evtl Luft nach oben bei dem Befehl hier\n    data = {}\n    for row in reader:\n            year = row[year_column]\n            if year not in data:\n                data[year] = [row]\n            else: \n                data[year].append(row) #data sorted by year\n    with open('Methods_2.csv', 'w', newline='') as target_file: \n        writer = csv.writer(target_file)\n        method_list = ['participat', 'creative', 'qualitative', 'quantitative', 'backcasting', 'brainstorming',  'citizen panel', 'conference', 'workshop', 'essay', 'expert panel', 'genius forecast', 'interview', 'literature review', 'morphological analysis',  'relevance tree', 'logic chart', 'logic diagram', 'role play', 'acting', 'scanning' , 'scenario workshop', 'science fictioning', 'simulation gaming', 'surveys', 'swot analysis', 'wildcard', 'benchmarking', 'bibliometrics', 'indicator',  'time series',  'modelling', 'patent analysis', 'extrapolation',  'cross-impact analysis',  'structural analysis', 'delphi', 'key technolog', 'critical technolog', 'multi-criteria', 'polling', 'voting', 'quantitative scenario', 'SMIC', 'roadmapping', 'stakeholder analysis', 'scenario', 'futures workshop']\n        header_w = ['Year', '# Publications with Data']+method_list\n        writer.writerow(header_w)\n        for year in data:\n            counter = {}\n            for method in method_list:\n                counter[method] = 0\n                counter_pubs = 0\n                for row in data[year]:\n                    search_space = row[title_column]+row[abstract_column]+row[KW_auto_column]+row[KW_manual_column]\n                   # print(search_space)\n                    if method in search_space.lower():\n                        counter[method] += 1\n                    if len(search_space) > 0:\n                        counter_pubs += 1\n            writer.writerow([year, counter_pubs]+[counter[method] for method in method_list])\n                       \nprint('Done')\n    ",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "['UID', 'Title', 'Year', 'Abstract', 'Auto Keywords', 'Manual Keywords', 'Country Count', 'Country List']\nDone\n"
        }
      ],
      "execution_count": 181
    }
  ]
}